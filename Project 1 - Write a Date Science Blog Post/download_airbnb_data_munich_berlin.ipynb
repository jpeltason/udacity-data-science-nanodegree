{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dataset download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook downloads the required data sets from Inside Airbnb. For the calendar data, multiple calendar data sets are put together, in order to cover the whole year 2019 in one calendar datat set.\n",
    "\n",
    "In detail, the following data sets are downloaded:\n",
    "* All available 'listings', 'reviews' and 'calendar' files for Munich and Berlin in 2018 and 2019.\n",
    "* 'Neighbourhood' geojson files for Munich and Berlin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up URL and file names for download\n",
    "\n",
    "base_url_munich_2019 = \"http://data.insideairbnb.com/germany/bv/munich/2019-\"\n",
    "base_url_munich_2018 = \"http://data.insideairbnb.com/germany/bv/munich/2018-\"\n",
    "\n",
    "base_url_berlin_2019 = \"http://data.insideairbnb.com/germany/be/berlin/2019-\"\n",
    "base_url_berlin_2018 = \"http://data.insideairbnb.com/germany/be/berlin/2018-\"\n",
    "\n",
    "\n",
    "listings_details_file = \"listings.csv.gz\"\n",
    "calendar_file = \"calendar.csv.gz\"\n",
    "reviews_details_file = \"reviews.csv.gz\"\n",
    "listings_file = \"listings.csv\"\n",
    "reviews_file = \"reviews.csv\"\n",
    "neighbourhoods_file = \"neighbourhoods.csv\"\n",
    "neigbourhoods_json_file = \"neighbourhoods.geojson\"\n",
    "\n",
    "file_names = [listings_details_file, calendar_file, reviews_details_file, listings_file, reviews_file, \n",
    "              neighbourhoods_file, neigbourhoods_json_file]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't know the exact date the data were made available, so we need to try out each day in the year\n",
    "# Set up arrays for months and days to iterate through\n",
    "\n",
    "months = np.array(range(1, 13)).astype(str)\n",
    "days = np.array(range(1, 32)).astype(str)\n",
    "\n",
    "def add_leading_zero(arr):\n",
    "    for i, el in enumerate(arr):\n",
    "        if (int(el) < 10):\n",
    "            arr[i] = \"0\" + el\n",
    "\n",
    "add_leading_zero(months)\n",
    "add_leading_zero(days)\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "import gzip, shutil\n",
    "def download_airbnb_files(base_url, file_name, folder_name, year_string):\n",
    "    for m in reversed(months):\n",
    "        for d in reversed(days):\n",
    "            url = base_url + m + '-' + d + '/data/' + file_name\n",
    "            prefix = folder_name + year_string + '_' + m + '_' + d + '_'\n",
    "            try:\n",
    "                #print(prefix + file_name)\n",
    "                #print(url)\n",
    "                with urllib.request.urlopen(url) as response, open(prefix + file_name, 'wb') as out_file:\n",
    "                    #print(url)\n",
    "                    #print(\"...downloaded file\")\n",
    "                    data = response.read() \n",
    "                    out_file.write(data)\n",
    "                    out_file.close()\n",
    "                    if (file_name != calendar_file): \n",
    "                        # only for the calender, we need all available files\n",
    "                        # for the other files, the latest file is enough\n",
    "                        return\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "\n",
    "for f in file_names:\n",
    "    download_airbnb_files(base_url_munich_2018, f, './Munich/', '2018')\n",
    "    download_airbnb_files(base_url_munich_2019, f, './Munich/', '2019')\n",
    "    download_airbnb_files(base_url_berlin_2018, f, './Berlin/', '2018')\n",
    "    download_airbnb_files(base_url_berlin_2019, f, './Berlin/', '2019')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019', '03', '15', 'calendar.csv']\n",
      "['2019', '03', '15', 'calendar.csv.gz']\n",
      "calendar.csv.gz\n",
      "['2019', '05', '22', 'calendar.csv']\n",
      "['2019', '05', '22', 'calendar.csv.gz']\n",
      "calendar.csv.gz\n",
      "['2019', '06', '24', 'calendar.csv']\n",
      "['2019', '06', '24', 'calendar.csv.gz']\n",
      "calendar.csv.gz\n",
      "['2019', '07', '16', 'calendar.csv']\n",
      "['2019', '07', '16', 'calendar.csv.gz']\n",
      "calendar.csv.gz\n",
      "['2019', '08', '24', 'calendar.csv']\n",
      "['2019', '08', '24', 'calendar.csv.gz']\n",
      "calendar.csv.gz\n",
      "['2019', '09', '24', 'calendar.csv']\n",
      "['2019', '09', '24', 'calendar.csv.gz']\n",
      "calendar.csv.gz\n",
      "['2019', '10', '20', 'calendar.csv']\n",
      "['2019', '10', '20', 'calendar.csv.gz']\n",
      "calendar.csv.gz\n",
      "['2019', '11', '25', 'calendar.csv']\n",
      "['2019', '11', '25', 'calendar.csv.gz']\n",
      "calendar.csv.gz\n",
      "['2019', '12', '26', 'calendar.csv']\n",
      "['2019', '12', '26', 'calendar.csv.gz']\n",
      "calendar.csv.gz\n",
      "['2019', '12', '26', 'listings.csv']\n",
      "['2019', '12', '26', 'listings.csv.gz']\n",
      "listings.csv.gz\n",
      "['2019', '12', '26', 'reviews.csv']\n",
      "['2019', '12', '26', 'reviews.csv.gz']\n",
      "['listings.csv']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-40a1dd164268>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mextract_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Munich/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mextract_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Berlin/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-40a1dd164268>\u001b[0m in \u001b[0;36mextract_files\u001b[1;34m(folder)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mparts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"calendar.csv.gz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def extract_files(folder):\n",
    "    directory = os.fsencode(folder)\n",
    "    for file_name in os.listdir(directory):\n",
    "        file_name = str(file_name).strip(\"b\\'\")\n",
    "        parts = file_name.split('_')\n",
    "        print(parts)\n",
    "        name = parts[3]\n",
    "            \n",
    "        if (name == \"calendar.csv.gz\"):\n",
    "            print(name)\n",
    "            # extract file, add date to file name\n",
    "            date = parts[0] + '_' + parts[1] + '_' + parts[2]\n",
    "            \n",
    "            with gzip.open(folder + file_name, 'r') as f_in, open(folder + date + '_calendar.csv', 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "    \n",
    "        elif (name == \"listings.csv.gz\"):\n",
    "            print(name)\n",
    "            # extract file\n",
    "            with gzip.open(folder + file_name, 'r') as f_in, open(folder + 'listings.csv', 'wb')as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "        elif (name == \"reviews.csv.gz\"):\n",
    "            # extract file\n",
    "            with gzip.open(folder + file_name, 'r') as f_in, open(folder + 'reviews.csv', 'wb')as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "\n",
    "extract_files('./Munich/')\n",
    "extract_files('./Berlin/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The neighbourhood information is not included, download from 2021\n",
    "berlin_neighbourhoods = \"http://data.insideairbnb.com/germany/be/berlin/2021-02-20/visualisations/neighbourhoods.csv\"\n",
    "berlin_neighbourhoods_json = \"http://data.insideairbnb.com/germany/be/berlin/2021-02-20/visualisations/neighbourhoods.geojson\"\n",
    "munich_neighbourhoods = \"http://data.insideairbnb.com/germany/bv/munich/2021-02-23/visualisations/neighbourhoods.csv\"\n",
    "munich_neighbourhoods_json = \"http://data.insideairbnb.com/germany/bv/munich/2021-02-23/visualisations/neighbourhoods.geojson\"\n",
    "\n",
    "def download_neighbourhood_airbnb_file(url, file_name, folder):\n",
    "    with urllib.request.urlopen(url) as response, open(folder + file_name, 'wb') as out_file:\n",
    "        data = response.read() \n",
    "        out_file.write(data)\n",
    "        out_file.close()\n",
    "\n",
    "download_neighbourhood_airbnb_file(berlin_neighbourhoods, 'neighbourhoods.csv', './Berlin/')\n",
    "download_neighbourhood_airbnb_file(berlin_neighbourhoods_json, 'neighbourhoods.geojson', './Berlin/')\n",
    "download_neighbourhood_airbnb_file(munich_neighbourhoods, 'neighbourhoods.csv', './Munich/')\n",
    "download_neighbourhood_airbnb_file(munich_neighbourhoods_json, 'neighbourhoods.geojson', './Munich/')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting together the calendar information for one year:\n",
    "def get_dates_and_file_names_of_cal_csvs(folder):\n",
    "    '''\n",
    "    Based on all calendar files in the given folder, \n",
    "    returns a dictionary whith a mapping from a datetime to the corresponding calendar file name.\n",
    "    '''\n",
    "    date_to_file_name = dict()\n",
    "    \n",
    "    # Build dict with the dates of each calendar files as key and the file name as value\n",
    "    directory = os.fsencode(folder)\n",
    "    for file_name in os.listdir(directory):\n",
    "        file_name = str(file_name).strip(\"b\\'\")\n",
    "        if (file_name.endswith('calendar.csv')):\n",
    "            parts = file_name.split('_')\n",
    "            name = parts[3]\n",
    "            date = datetime.datetime(int(parts[0]), int(parts[1]), int(parts[2]))\n",
    "            date_to_file_name[date] = file_name\n",
    "    return date_to_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_cal_dfs(folder):\n",
    "    '''\n",
    "    Returns a DataFrame put together based on all available calendar files in the given folder.\n",
    "    Considers from each calendar file only those days before the next calendar file begins.\n",
    "    The DateFrame lists for each date of the year the average price, number of available listings, \n",
    "    and number of bookings, as well as the occupancy rate (bookings / listings)\n",
    "    '''\n",
    "    print(folder)\n",
    "     \n",
    "    # Build dict with dates and corresponding file names\n",
    "    date_to_file_name = get_dates_and_file_names_of_cal_csvs(folder)\n",
    "        \n",
    "    # For each date, read in the corresponding csv file\n",
    "    # Consider only data points before next file begins\n",
    "    # Do some data cleaning and wrangling\n",
    "    dates = list(date_to_file_name.keys())\n",
    "    year_df = pd.DataFrame([])\n",
    "    for i in range(len(dates)):\n",
    "        \n",
    "        date = dates[i]\n",
    "        df = pd.read_csv(folder + date_to_file_name[date], parse_dates=['date'])\n",
    "           \n",
    "        if (i < len(dates)-1):\n",
    "            next_date = dates[i+1]\n",
    "            \n",
    "            df_next = pd.read_csv(folder + date_to_file_name[next_date], parse_dates=['date'])\n",
    "            next_date_in_csv = df_next['date'].min()\n",
    "            print(next_date_in_csv)\n",
    "            \n",
    "            # only the listings until the next dataframe begins\n",
    "            df = df[df['date'] < next_date_in_csv]\n",
    "        else:\n",
    "            df = df[df['date'] < datetime.datetime(2020, 1, 1)]\n",
    "        \n",
    "        # Convert 'price' and 'adjusted_price' to float\n",
    "        if 'price' in df.columns:\n",
    "            df['price'] = df['price'].str.replace(',', '').str.strip('$').astype(float)\n",
    "        if 'adjusted_price' in df.columns:\n",
    "            df['adjusted_price'] = df['adjusted_price'].str.replace(',', '').str.strip('$').astype(float)\n",
    "                        \n",
    "        # Convert 'available' to boolean\n",
    "        df['available'] = df['available'].map({'t': True, 'f': False})\n",
    "        \n",
    "        # Add dummy column for count aggregation\n",
    "        df['listings'] = 1\n",
    "        # group by date, keep mean for 'available' and 'price' and count for 'listings'\n",
    "        df = df.groupby('date').agg({'available': ['mean'], 'price': ['mean'], 'listings': ['count']})\n",
    "        df['available'] = 1-df['available']\n",
    "        df = df.rename(columns={'available':'occupancy'})\n",
    "        \n",
    "        # Add column indicating the date of the calendar file used\n",
    "        df['calendar_file_date'] = date\n",
    "        \n",
    "        df.columns = df.columns.get_level_values(0)\n",
    "        \n",
    "        # append this to year_df\n",
    "        year_df = year_df.append(df)\n",
    "        \n",
    "    # Retrieve number of bookings from occupancy rate and number of listings \n",
    "    year_df['bookings'] = year_df['occupancy'] * year_df['listings']\n",
    "    return year_df\n",
    "\n",
    "year_df_m = read_cal_dfs('./Munich/')\n",
    "year_df_b = read_cal_dfs('./Berlin/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_to_file_name = get_dates_and_file_names_of_cal_csvs('./Munich/')\n",
    "dates = list(date_to_file_name.keys())\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_df_m.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write calendar files to csv\n",
    "year_df_m.to_csv('./data/year_2019_Munich.csv')\n",
    "\n",
    "year_df_b_2019 = year_df_b[year_df_b.index > datetime.datetime(2018, 12, 1)]\n",
    "year_df_b_2019.to_csv('./data/year_2019_Berlin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
